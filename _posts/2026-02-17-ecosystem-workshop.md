---
layout: irispost
title: "Ecosystems to Drive Discovery: The High-Energy Physics Community Gathers to Coordinate Efforts on Software and Computing Research and Development"
author: Adam Hadhazy
image: /assets/images/posts/2026-02-17-ecosystem-workshop-image1.jpg
image-whole: true
image-caption: >
    Group photo of the Coordinate Ecosystem for HEP Software and Computing workshop participants
    at the Keough School in Washington, DC on December 3-5, 2025, with an inset showing several
    remote participants.
summary: >
    In December 2025, IRIS-HEP convened a landmark workshop in Washington, DC, bringing together
    the high-energy physics community to coordinate software and computing R&D efforts in
    preparation for the HL-LHC and future experiments, with discussions spanning AI integration,
    shared software ecosystems, and green computing.
figure-class: center
---

The metaphor "finding a needle in a haystack" offers an inkling of the challenge faced by modern
physicists working in the high-energy realm.

Every second at the Large Hadron Collider—the largest machine ever built—more than a billion
protons collide, shattering into trillions of even smaller particles, ultimately generating a
whopping petabyte of data. To filter and process these accumulating data haystacks in pursuit of
rare, short-lived particles, researchers must rely on an ecosystem of highly sophisticated software
and computer hardware.

The scale of this proverbial needle-finding is set to grow substantially with the LHC's upcoming
enhancement into the High Luminosity LHC (HL-LHC), along with a slew of planned new particle
accelerators and experiments. To help address the formidable computing obstacles ahead, the
National Science Foundation (NSF) funded the [Institute for Research and Innovation in Software
for High Energy Physics](https://iris-hep.org/) (IRIS-HEP) in September 2018 and renewed the
funding in 2023. This past December, IRIS-HEP convened a workshop dedicated to coordinating the
research and development efforts underway that are preparing the next generation of elaborate
software and computing ecosystems needed to drive scientific discovery.

{% include figure.html
    file="/assets/images/posts/2026-02-17-ecosystem-workshop-image3.jpg"
    alt="Workshop attendees gathered at the Keough School of Global Affairs in Washington, DC"
    caption="Workshop attendees at the University of Notre Dame's Keough School of Global Affairs,
    Washington, DC. Credit: IRIS-HEP"
    img-style="max-width: 100%;height: auto"
    class="center"
%}

The meeting brought together a wide swath of the high-energy physics community. In attendance were
representatives from the IRIS-HEP team, other large R&D efforts, United States funding agencies,
national and international laboratories, and software and computing management for projects
including the HL-LHC, the Deep Underground Neutrino Experiment (DUNE), the Electron Ion Collider
(EIC), and the potential Future Circular Collider (FCC) and Muon Collider.

Over the course of the workshop, the attendees sought to explore and establish alignment within the
broad R&D program for high-energy physics, as well as identify emerging opportunities for
collaboration.

"With the HL-LHC scheduled to begin taking data as soon as 2030 and other exciting projects on the
horizon, we want to optimize our collective efforts toward developing powerful new computing
approaches," says [Gordon Watts](https://phys.washington.edu/people/gordon-watts), a professor of
physics at the University of Washington who serves as IRIS-HEP co-Principal Investigator and
Deputy Executive Director.

Topics discussed included the status and timelines of R&D deliverables, domestic funding and its
intersection with international efforts, areas of common R&D and what to prioritize, and how to
conduct massive processing tasks in energy-efficient ways.

"We all really benefitted from getting in the same room and figuring out where everybody is in
terms of their development and their needs and gaining a coherent view of the challenges ahead,"
says Zachary Marshall, a senior scientist at Lawrence Berkeley National Laboratory, who presented
at the workshop.

"We have an exciting diversity of challenges right now," says fellow attendee Tova Holmes, an
associate professor of experimental high energy particle physics at the University of Tennessee,
Knoxville and a leader of the Muon Collider project. "We're trying to figure out how to run our
own analysis on the data that we are still collecting at the LHC, while preparing upgrades and
trying to get all of the software working for the data storm that's coming with the HL-LHC, and at
the same time looking many years down the road to these future collider experiments."

"It's a tough lift to do all of that at once as a community, but I do think we're up to it," added
Holmes. "IRIS-HEP and these workshops are a really great way to start formulating how that can be
done."

## Scaling Up and Developing Anew

Compared to the original LHC that started smashing particles in 2009, collision rates at the
upcoming HL-LHC will ramp up three or four times, increasing data rates at least an order of
magnitude. The resulting data deluge will advance understanding of the Higgs boson, the
mass-imparting fundamental particle famously discovered via the LHC. The data haul will also push
toward new physics beyond the successful, yet significantly incomplete framework known as the
Standard Model.

To this end, the high-energy physics community's work on upgrading the computational
infrastructure is proceeding apace, with careful attention being paid to avoiding duplicative
efforts while also creating leverageable platforms for colliders that will not run until the 2050s.
The IRIS-HEP workshop helped bring the long-term outlook into better focus, Marshall says.

"When you extrapolate resource requirements out that far, of course there's huge uncertainty in
terms of what industry is going to be able to do in the next 25 years," Marshall says. "But even
just naively scaling what the HL-LHC will do, you're getting within that envelope of what some
future colliders might need. So it could be that we have an opportunity to be more aggressive
dealing with data volumes in terms of processing techniques to make the science faster or more
granular, and that's something we'll be thinking about a lot over the next 5-10 years."

A critical enabler of this next stage of high-energy physics research, as well as across many
other scientific and engineering fields, is artificial intelligence. Workshop attendees discussed
how AI technologies might be best utilized. One such takeaway: AI could ably assist in updating
legacy software for new experiments, a tedious but critical task. A group of workshop attendees
plans to craft a white paper to identify further opportunities for AI application and innovation.

Relatedly, around the time of the workshop, the current Administration announced the "Genesis
Mission," a Department of Energy-led initiative to develop a new AI platform to accelerate
scientific discovery through integration of national labs, universities, and private sector
partners. "We're interested in seeing what we can do for the Genesis Mission and what the Genesis
Mission can do for us," says Marshall.

Another key takeaway from the conference was what Marshall described as the "surprisingly high
amount of commonality" around a particular software suite called Key4HEP. As a unified software
stack that supports detector simulation and analysis, the suite has been developed collaboratively
by various groups in the future collider community. Marshall envisions pulling some HL-LHC software
into the suite and encouraging the community to feed back their developments into it, helping to
harmonize efforts and making the suite as robust as possible. Speaking further to its
functionality, the Muon Collider group is also actively transitioning to Key4HEP. "I think this is
one of those really nice, high-leverage opportunities where you do a little and you get a lot,"
says Marshall.

## Green Computing to the Fore

The workshop also touched on sustainability as an important theme underlying coordination across
next-generation high-energy physics computing ecosystems. A chief concern is addressing the high
electricity demands for computation—a growing problem in the public consciousness thanks to
expanding data centers and rising energy costs.

Marshall has studied the environmental impacts of high-energy computing in relation to his prior
role as computing coordinator for the ATLAS experiment at the LHC. He is a contributing author on
papers and reports that have specifically looked at the carbon footprint and sustainability of the
ATLAS computing infrastructure.

Looking ahead, he says that greater awareness in the community is the obvious first step, followed
by data-center-specific efficiency gains ranging from simple lighting upgrades to sophisticated
rack heat management. Further opportunities lie in efficient scheduling of compute and physical
magnetic tape handling tasks, as well as computing models that make smarter decisions about where
data is distributed and processed. Toward this end, the creation of a "digital twin" of the
worldwide LHC computing grid is being pursued to provide a sandbox for testing new model
techniques.

"I think now is the sort of moment, because we're just about to scale for the HL-LHC, where we
want to see a lot of these green computing things start to happen for the future," says Marshall.

Overall, the workshop attendees left invigorated and ready to progress their shared enterprise of
high-energy physics computing.

"I think that our community is really good at building collaborations that can take on hard
challenges," says Holmes. "We need to just figure out how to do that in this current context,
where we're pushing ourselves to simultaneously solve these tough challenges across many different
scopes and experiments, taking on perhaps more than we ever have before. That's why IRIS-HEP and
workshops like this are so important."