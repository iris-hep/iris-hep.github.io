---
layout: codas-hep-participant
e-mail: iosborne@princeton.edu
institution: Princeton University
name: Ianna Osborne
photo: "/assets/images/team/Ianna-Osborne.png"
github-username: ianna
linkedin-profile: "https://linkedin.com/in/ianna-osborne-9982a342"
orcid: 0000-0002-6955-1033
title: Research Software Engineer, Princeton University
website:
logos:
    - /assets/images/codas-hep/logos/Princeton_logo.png
    - /assets/images/codas-hep/logos/Iris-hep-logo.png
    - /assets/logos/skhep-logo.svg
    - /assets/logos/awkward.svg
---

## My research:
I am a Research Software Engineer specializing in open-source software development within the Python ecosystem and Julia for fundamental physics. My work focuses on designing and optimizing software for high-energy physics (HEP) data analysis.

In the past, I contributed extensively to CMS software (CMSSW), particularly in geometry description, simulation, and event display. My expertise spans software architecture, numerical optimization, and large-scale scientific computing, with a strong focus on enhancing data analysis tools for physics research.

## My expertise is:
   - *Programming Languages:* C++, Python, Julia
   - *Technologies:* Awkward Array, Numba, Just-in-Time Compilation
   - *Integration:* Python integration with other languages
   - *Software Development:* Open-source contributions in Python and Julia ecosystems
   - *Scientific Computing:* Geometry modeling, simulation, event visualization
   - *Configuration & Deployment:* Managing and distributing complex software environments

## A problem I'm grappling with:
I am currently focused on integrating Awkward Array with Numba to optimize performance through Just-in-Time compilation techniques. Additionally, I am exploring Python on GPU to leverage parallel computing power for complex data analysis.

## I've got my eyes on:
   - High-performance computing (HPC) applications in fundamental physics
   - Large-scale parallelism and deep storage hierarchies for HEP data
   - Juliaâ€™s potential for optimizing scientific computing workflows

## I want to know more about:
To further improve my work, I am keen to deepen my understanding of:

   - Optimizing data movement and storage for large-scale scientific workflows
   - Heterogeneous computing to leverage CPUs, GPUs, and specialized accelerators
   - Efficient memory management strategies for structured and unstructured data
   - Scalable distributed systems that handle massive physics datasets

By exploring these areas, I aim to contribute to more efficient and scalable computational solutions for HEP.
